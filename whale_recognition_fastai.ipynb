{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swimming Mammal Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try and buil a ML algorithm that is capable of identifying almost 28k unique individual marine mammals belonging to 30 species.\n",
    "\n",
    "Dataset can be downloaded from [here](https://www.kaggle.com/bdsaglam/happy-whale-512?select=sample_submission.csv). This is the \"simplified version\" of the [original dataset](https://www.kaggle.com/c/happy-whale-and-dolphin/data) in that all the figures have the same size (512x512) -- if smaller they have been padded. \n",
    "\n",
    "The files are already divided into train and test folders, although there is no `species` label associated to each test image. *** Review this ***\n",
    "\n",
    "My idea is:\n",
    "1. train a non-pretrained resnet34 network from scratches (`xresnet34` in the fastai libraries);\n",
    "1. train a pretrained resnet34 network;\n",
    "1. compare the results and comment on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Initial imports and setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fastai\n",
    "# fastai.__version__ \n",
    "# 2.5.3\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback import *\n",
    "from fastai.metrics import error_rate\n",
    "import pandas as pd\n",
    "import os, csv\n",
    "\n",
    "#! Fixing issues with parallel processes (or at least suppressing Warnings...)\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining all the paths and reading the csv file containing the labels (i.e. the mammal species) associated to each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path +='/archive'\n",
    "path_images = path+'/train_images/'\n",
    "path_img = path+'/train.csv'\n",
    "#* Read csv file using pandas\n",
    "df =pd.read_csv(path_img)\n",
    "#df.head\t#* printing datafile names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dictionary with the structure:\n",
    "\n",
    "```\n",
    "\timage_name: species\n",
    "```\n",
    "\n",
    "and the function to retrieve the species starting from the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = {}\n",
    "with open(path_img) as file:\n",
    "\treader = csv.DictReader(file)\n",
    "\tfor row in reader:\n",
    "\t\tspecies[row['image']] = row['species']\n",
    "\n",
    "def label_func(fname):\n",
    "    return species[str(fname).split('/')[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our ***dataset*** we want to create a dataloader for it, that splits the dataset into a *test* and a *training* set. Images are resized to 64x64 in order to make the process quicker on a laptop, and are padded if necessary (should not, since the images I refer to in the link above are all larger).\n",
    "\n",
    "I load the images from the folder specified in `path/train_images` using the labels loaded from the csv file, saved in `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_df(df, \n",
    "\tpath,\n",
    "\tfolder = 'train_images',\n",
    "\titem_tfms=Resize(64,method=ResizeMethod.Pad),\n",
    "\tbatch_tfms=Normalize.from_stats(*imagenet_stats))\n",
    "\n",
    "# dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all images in subfolders\n",
    "fnames = get_image_files(path)\n",
    "#fnames[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now create the DataBlock, i.e. how to assemble data as follows:\n",
    "\n",
    "1. grab the images with the built-in feature `get_image_files`;\n",
    "1. grab the species associated to each image using the function I have defined above `label_func`;\n",
    "1. transform the images, resizing them to 64x64 and padding them;\n",
    "1. splitting the images into a validation and training set, setting myself a `seed` for the random number generator;\n",
    "1. normalising the images within the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "\tget_items = get_image_files,\n",
    "\tget_y = label_func,\n",
    "\titem_tfms=Resize(64,method=ResizeMethod.Pad),\n",
    "\tsplitter=RandomSplitter(valid_pct=.1, seed=42),\n",
    "\t# batch_tfms=[*aug_transforms(size=64, max_warp=0), Normalize.from_stats(*imagenet_stats)]\n",
    "\tbatch_tfms=Normalize.from_stats(*imagenet_stats)\n",
    "\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = dblock.datasets(path)\n",
    "no_species = len(dsets.vocab) # returns the total number of species\n",
    "# dsets.train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to do anything else since the images are already of size 512x512 and if smaller, these are patched.\n",
    "\n",
    "We can now transform the DataBlock into DataLoaders, using a batchsize of 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(path_images)\n",
    "# dls.show_batch(max_n=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train a model from scratch since there is no such a pre-trained NN.\n",
    "\n",
    "We might use a CNN learner with the `pretrained` option set to `False`, or otherwise we can a set of resnet models that have \"all the tricks from modern research incorporated\". Basically I use xresnet34 and xresnet50 models, specifying the number of classes we expect to see as a result, and nothing else. I will do and comment all the steps for the xresnet34 and then repeat them all in the xresnet50 case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xresnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define here two models to use for fitting, namely xresnet34 and xresnet50 with no particular activation functions or any further specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netw34_subopt = xresnet34(n_out=no_species, pretrained = False)\n",
    "# netw34_subopt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launching the learning process. In order to do so, I specify the metrics, `accuracy` and `error_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn34_subopt = Learner(dls,model = netw34_subopt, metrics =[accuracy,error_rate])\n",
    "#  metrics=[partial(accuracy_multi, thresh=0.85)], loss_func=BCEWithLogitsLossFlat(thresh=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I launch the learning process without any suggestion about the learning rate, and see how it goes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\tvalid_loss\taccuracy\terror_rate\ttime\n",
    "0\t1.095772\t1.174001\t0.635509\t0.364491\t29:32\n",
    "1\t0.738535\t0.781627\t0.756026\t0.243974\t29:50\n",
    "2\t0.505455\t0.569351\t0.820694\t0.179306\t31:07\n",
    "3\t0.301352\t0.420873\t0.866745\t0.133255\t29:24\n",
    "4\t0.186283\t0.377023\t0.881246\t0.118754\t29:47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn34_subopt.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now try and optimise the learning rate, re-launching the `fit_one_cycle` procedure with the optimal lr obtained with `lr_find()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn34_subopt.save('dorsal_xresnet34_v1')\n",
    "# learn34_subopt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn34_subopt.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell yields:\n",
    "\n",
    "| epoch | train_loss | valid_loss | accuracy | error_rate | time |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 0.180385 | 0.379558 | 0.881246 | 0.118754 | 29:57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn34_subopt.fit_one_cycle(1,4e-5)\n",
    "# Yields: \n",
    "#epoch\ttrain_loss\tvalid_loss\taccuracy\terror_rate\ttime\n",
    "#0\t0.180385\t0.379558\t0.881246\t0.118754\t29:57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn34_subopt.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp34 = Interpretation.from_learner(learn34_subopt)\n",
    "interp34. plot_top_losses(16,figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn34_subopt.save('dorsal_xresnet34_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xresnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netw50_subopt = xresnet50(n_out=no_species, pretrained = False)\n",
    "learn50_subopt = Learner(dls,model = netw50_subopt, metrics=[accuracy,error_rate,Precision(),Recall()])\n",
    "# netw50_subopt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn50_subopt.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn50_subopt.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn50_subopt.fit_one_cycle(3,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn50_subopt.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp50 = Interpretation.from_learner(learn50_subopt)\n",
    "interp50. plot_top_losses(16,figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn50_subopt.save('dorsal_xresnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn50.save('dorsal_fin_resnet50_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn50.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock2 = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "\tget_items = get_image_files,\n",
    "\tget_y = label_func,\n",
    "\titem_tfms=Resize(256,method=ResizeMethod.Pad),\n",
    "\tsplitter=RandomSplitter(valid_pct=.1, seed=42),\n",
    "\tbatch_tfms=[*aug_transforms(size=128, max_warp=0), Normalize.from_stats(*imagenet_stats)]\n",
    "\t# batch_tfms=Normalize.from_stats(*imagenet_stats)\n",
    "\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls2 = dblock2.dataloaders(\n",
    "\tpath_images\n",
    "\t# multiprocessing_context=torch.multiprocessing.get_context('spawn')\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netw34_opt = xresnet34(n_out=no_species, pretrained = False)\n",
    "learn34_opt = Learner(dls2,model = netw34_opt, metrics =[accuracy,error_rate])\n",
    "learn34_opt.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls2, resnet34, metrics=error_rate)\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what results we have got. \n",
    "\n",
    "We will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not. In this case the mistakes look reasonable (none of the mistakes seems obviously naive). This is an indicator that our classifier is working correctly. \n",
    "\n",
    "Furthermore, when we plot the confusion matrix, we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. This suggests that it just finds it difficult to distinguish some specific categories between each other; this is normal behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn34_subopt.load('dorsal_fin_1')\n",
    "#learn50.load('dorsal_fin_resnet50_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn34_subopt)\n",
    "#interp50 = ClassificationInterpretation.from_learner(learn50)\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "# losses50,idxs50 = interp50.top_losses()\n",
    "\n",
    "len(dls.valid_ds)==len(losses)==len(idxs)\n",
    "# len(dls.valid_ds)==len(losses50)==len(idxs50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp50.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(interp.plot_top_losses)\n",
    "doc(interp50.plot_top_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n",
    "interp50.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp50.most_confused(min_val=2)\n",
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreezing, fine-tuning, and learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model is working as we expect it to, we will *unfreeze* our model and train some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, that didn't really help. Good lesson to learn: just increasing the number of epochs may not always be a good strategy. Let's try something else. The \"learning rate\" is a *hyperparameter* that determines how quickly we make changes to the weights of the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('pets-stage-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty accurate model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train in the same way as before but with one caveat: instead of using resnet34 as our backbone we will use resnet50 (resnet34 is a 34 layer residual network while resnet50 has 50 layers. It will be explained later in the course and you can learn the details in the [resnet paper](https://arxiv.org/pdf/1512.03385.pdf)).\n",
    "\n",
    "Basically, resnet50 usually performs better because it is a deeper network with more parameters. Let's see if we can achieve a higher performance here. To help it along, let's us use larger images too, since that way the network can see more detail. We reduce the batch size a bit since otherwise this larger network will require more GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(),\n",
    "                                   size=299, bs=bs//2).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet50, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('pets-stage-1-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('pets-stage-1-50');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's astonishing that it's possible to recognize pet breeds so accurately! Let's see if full fine-tuning helps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it doesn't, you can always go back to your previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('pets-stage-1-50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=False)\n",
    "data = ImageDataBunch.from_folder(path, ds_tfms=tfms, size=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet18, metrics=accuracy)\n",
    "learn.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'labels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_csv(path, ds_tfms=tfms, size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(5,5))\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_df(path, df, ds_tfms=tfms, size=24)\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_paths = [path/name for name in df['name']]; fn_paths[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = r\"/(\\d)/\\d+\\.png$\"\n",
    "data = ImageDataBunch.from_name_re(path, fn_paths, pat=pat, ds_tfms=tfms, size=24)\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_name_func(path, fn_paths, ds_tfms=tfms, size=24,\n",
    "        label_func = lambda x: '3' if '/3/' in str(x) else '7')\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [('3' if '/3/' in str(x) else '7') for x in fn_paths]\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_lists(path, fn_paths, labels=labels, ds_tfms=tfms, size=24)\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(ImageDataBunch.from_name_re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
